{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "486717d1-2458-4f1c-86a0-fa00da24aa5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import IFrame\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_colwidth',150)\n",
    "pd.set_option('display.max_columns',150)\n",
    "pd.set_option('display.max_rows',500)\n",
    "\n",
    "plt.style.use('bmh')\n",
    "\n",
    "from collections import OrderedDict\n",
    "from pandas import ExcelWriter\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime as dt\n",
    "from tqdm import tqdm\n",
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "import gc\n",
    "import itertools\n",
    "from glob import glob\n",
    "import shutil\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import sweetviz\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import feature_selection\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from window_ops.rolling import rolling_mean, rolling_max, rolling_min, seasonal_rolling_mean\n",
    "from numba import njit\n",
    "\n",
    "import mlforecast\n",
    "from mlforecast import MLForecast\n",
    "from mlforecast import target_transforms\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "687e58f3-9497-4844-b71e-488d464694f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_preprocessing(df):\n",
    "    '''\n",
    "    Data preprocessing function.\n",
    "    df - dataframe with at least 2 columns: \n",
    "        - date - day of metar string\n",
    "        - metar - METAR string\n",
    "    '''\n",
    "    # clean from RMK - we don't need\n",
    "    df['metar'] = df['metar'].map(lambda x: x.split(' RMK')[0].strip().replace('SPECI ',''))\n",
    "    df = df[df.metar.str[:4].isin(['KMIA','SPEC'])].reset_index(drop = True)\n",
    "\n",
    "    # parsing\n",
    "    from metar import Metar\n",
    "    def parse_metar(x):\n",
    "        try:\n",
    "            m = Metar.Metar(x.metar, month = x.date.month, year = x.date.year)\n",
    "        except Exception as e:\n",
    "            m = Metar.Metar(x.metar[:4], month = x.date.month, year = x.date.year)\n",
    "        return m\n",
    "    out = df.apply(parse_metar, axis = 1)\n",
    "    df_out = pd.DataFrame([x.__dict__ for x in out])\n",
    "\n",
    "    # choose only useful features\n",
    "    feats_used = [\n",
    "        'time',\n",
    "        'wind_dir',\n",
    "        'wind_speed',\n",
    "        'wind_gust',\n",
    "        'vis',\n",
    "        'temp',\n",
    "        'dewpt',\n",
    "        'press',\n",
    "        'weather',\n",
    "        'sky',\n",
    "        # 'code',\n",
    "    ]\n",
    "    df_out = df_out[feats_used]\n",
    "\n",
    "    # time preprocessing\n",
    "    f1 = df_out.time.isnull()\n",
    "    df_out = df_out[~f1].sort_values('time').reset_index().set_index('time')\n",
    "    del df_out['index']\n",
    "    df_out = df_out.resample('H').last()\n",
    "    \n",
    "    ####\n",
    "    # values convertion\n",
    "    # get values\n",
    "    def conv_val(x):\n",
    "        try:\n",
    "            return x.value()\n",
    "        except:\n",
    "            return np.nan\n",
    "    \n",
    "    ####################\n",
    "    # numerical features\n",
    "    df_out['wind_dir'] = df_out['wind_dir'].map(conv_val)\n",
    "    df_out['wind_speed'] = df_out['wind_speed'].map(conv_val)\n",
    "    df_out['wind_gust'] = df_out['wind_gust'].map(conv_val)\n",
    "    df_out['vis'] = df_out['vis'].map(conv_val)\n",
    "    df_out['temp'] = df_out['temp'].map(conv_val)\n",
    "    df_out['dewpt'] = df_out['dewpt'].map(conv_val)\n",
    "    df_out['press'] = df_out['press'].map(conv_val)\n",
    "    \n",
    "    # corrections\n",
    "    df_out.loc[df_out['wind_dir'] == 0,   'wind_dir'] = np.nan\n",
    "    df_out.loc[df_out['wind_speed'] == 0, 'wind_gust'] = np.nan\n",
    "    \n",
    "    # fill nulls by the forward fill method\n",
    "    feats_fill = ['temp','dewpt','press','vis','wind_speed']\n",
    "    for feat in feats_fill:\n",
    "        df_out[feat] = df_out[feat].fillna(method = 'ffill').fillna(method = 'bfill')\n",
    "        \n",
    "    # add flags that have value\n",
    "    df_out['vis_unclear_flg'] = (df_out['vis'] < 10).astype(int)\n",
    "    df_out['wind_speed_flg'] = (df_out['wind_speed'] > 0).astype(int)\n",
    "    df_out['wind_gust_flg'] = (df_out['wind_gust'].notnull()).astype(int)\n",
    "    df_out['wind_dir_flg'] = (df_out['wind_dir'].notnull()).astype(int)\n",
    "    \n",
    "    # fill nulls again\n",
    "    df_out['wind_dir'] = df_out['wind_dir'].fillna(method = 'ffill').fillna(method = 'bfill')\n",
    "    df_out['wind_gust'] = df_out['wind_gust'].fillna(method = 'ffill').fillna(method = 'bfill')\n",
    "    \n",
    "        \n",
    "    #######################\n",
    "    # categorical features\n",
    "    df_out['id1'] = range(len(df_out))\n",
    "    def conv_list(df, feat):\n",
    "        '''\n",
    "        # unflat lists\n",
    "        '''\n",
    "        out1 = list()\n",
    "        out2 = list()\n",
    "        for _, r in df.iterrows():\n",
    "            out1+=r[feat]\n",
    "            out2+=[r.id1]*len(r[feat])\n",
    "        df1 = pd.DataFrame(out1)\n",
    "        df1['id1'] = out2\n",
    "        return df1\n",
    "\n",
    "    \n",
    "    # weather\n",
    "    df1 = df_out[~df_out['weather'].isnull()]\n",
    "    df1 = df1[df1['weather'].map(len) > 0][['weather','id1']]\n",
    "    df2 = conv_list(df1, 'weather')\n",
    "    \n",
    "    df2['weather_rain'] = 0\n",
    "    df2.loc[(df2[0] == '-') & (df2[2].isin(['RA','DZ'])), 'weather_rain'] = 1\n",
    "    df2.loc[(df2[0] == '')  & (df2[2].isin(['RA','DZ'])), 'weather_rain'] = 2\n",
    "    df2.loc[(df2[0] == '+') & (df2[2].isin(['RA','DZ'])), 'weather_rain'] = 3\n",
    "    df2['weather_rain_flg'] = (df2['weather_rain'] > 0).astype(int)\n",
    "\n",
    "    df2['weather_ts'] = 0\n",
    "    df2.loc[(df2[1] == 'TS'), 'weather_ts'] = 1\n",
    "\n",
    "    df2['weather_fog'] = 0\n",
    "    df2.loc[(df2[3].isin(['BR'])), 'weather_fog'] = 1\n",
    "    df2.loc[(df2[3].isin(['HZ'])), 'weather_fog'] = 2\n",
    "    df2.loc[(df2[3].isin(['FG'])), 'weather_fog'] = 3\n",
    "    df2.loc[(df2[3].isin(['FU'])), 'weather_fog'] = 4\n",
    "    df2['weather_fog_flg'] = (df2['weather_fog'] > 0).astype(int)\n",
    "    \n",
    "    feats1 = ['weather_rain', 'weather_rain_flg', 'weather_ts', 'weather_fog', 'weather_fog_flg']\n",
    "    df3 = df2.groupby('id1')[feats1].max().reset_index()\n",
    "    ind = df_out.index\n",
    "    df_out = df_out.merge(df3[['id1'] + feats1], how = 'left', on = 'id1')\n",
    "    df_out.index = ind\n",
    "    for f in feats1:\n",
    "        df_out[f] = df_out[f].fillna(0)\n",
    "    \n",
    "    del df1\n",
    "    del df2\n",
    "    gc.collect()\n",
    "    \n",
    "    # sky\n",
    "    df1 = df_out[~df_out['sky'].isnull()]\n",
    "    df1 = df1[df1['sky'].map(len) > 0][['sky','id1']]\n",
    "    df2 = conv_list(df1, 'sky')\n",
    "    \n",
    "    df2[1] = df2[1].map(conv_val).fillna(0)\n",
    "    df2[2] = df2[2].fillna('')\n",
    "    \n",
    "    df21 = pd.concat([\n",
    "        df2[['id1',0,1]].rename(columns = {0:'var'}), \n",
    "        df2[['id1',2,1]].rename(columns = {2:'var'}) ])\n",
    "    sky_used = ['BKN','FEW','SCT','OVC','CLR','CB','TCU']\n",
    "    filt = df21['var'].isin(sky_used)\n",
    "    \n",
    "    df3 = df21[filt].groupby(['id1','var']).size().unstack().fillna(0)\n",
    "    cols = df3.columns\n",
    "    pre = 'sky_cnt_'\n",
    "    df3.columns = [pre+c for c in cols]\n",
    "    ind = df_out.index\n",
    "    df_out = df_out.merge(df3.reset_index(), how = 'left')\n",
    "    df_out.index = ind\n",
    "    for f in sky_used:\n",
    "        df_out[pre+f] = df_out[pre+f].fillna(0)\n",
    "        df_out['sky_flg_'+f] = (df_out[pre+f] > 0).astype(int)\n",
    "\n",
    "    df3 = df21[filt].groupby(['id1','var'])[1].mean().unstack().fillna(0)\n",
    "    cols = df3.columns\n",
    "    pre = 'sky_avg_'\n",
    "    df3.columns = [pre+c for c in cols]\n",
    "    ind = df_out.index\n",
    "    df_out = df_out.merge(df3.reset_index(), how = 'left')\n",
    "    df_out.index = ind\n",
    "    for f in sky_used:\n",
    "        df_out[pre+f] = df_out[pre+f].fillna(0)\n",
    "        \n",
    "    del df1\n",
    "    del df2\n",
    "    del df21\n",
    "    del df3\n",
    "    gc.collect()\n",
    "    \n",
    "    # del df_out['sky']\n",
    "    del df_out['weather']\n",
    "    del df_out['id1']\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1feb9e33-3562-470e-98de-af505f7757b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_features(df, feats):\n",
    "    '''\n",
    "    Feature engineering function.\n",
    "    '''\n",
    "    df = df.reset_index()\n",
    "    df['unique_id'] = 'a'\n",
    "\n",
    "    # feature engine\n",
    "    model = MLForecast(\n",
    "        models = {},\n",
    "        freq = 'H',\n",
    "        target_transforms = [\n",
    "        ],\n",
    "        lags = [1] + [24],\n",
    "        lag_transforms = {\n",
    "            1:  [\n",
    "                (rolling_mean, 3),\n",
    "                (seasonal_rolling_mean, 24, 3), \n",
    "            ],\n",
    "        },\n",
    "        # date_features=['month','hour'],\n",
    "    )\n",
    "    # main feats\n",
    "    df_all = df[['time']]\n",
    "    for feat in feats:\n",
    "        feats0 = ['unique_id','time',feat]\n",
    "        df1 = model.preprocess(df[feats0], id_col = 'unique_id', time_col = 'time', target_col = feat)\n",
    "        del df1['unique_id']\n",
    "        cols = [f'{feat}_'+c.replace('rolling_mean','RM').replace('window_size','WS').replace('seasonal','S').replace('season_length','SL') for c in list(df1.columns)[2:]]\n",
    "        df1.columns = list(df1.columns)[:2] + cols\n",
    "\n",
    "        eps = 1e-12\n",
    "        df1[f'{feat}_lag1to3'] = df1[f'{feat}_lag1'] / (df1[f'{feat}_RM_lag1_WS3'] + eps)\n",
    "        df1[f'{feat}_lag24to72'] = df1[f'{feat}_lag24'] / (df1[f'{feat}_S_RM_lag1_SL24_WS3'] + eps)\n",
    "\n",
    "        df_all = df_all.merge(df1, on = 'time', how = 'left')\n",
    "        \n",
    "    # date feats\n",
    "    df_all['dt_month'] = df_all['time'].dt.month\n",
    "    df_all['dt_hour'] = df_all['time'].dt.hour\n",
    "    \n",
    "    # return df_all\n",
    "    return df_all[df_all.wind_dir.notnull()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
